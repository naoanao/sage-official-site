"""
Course Production Pipeline
Automated online course generation with AI

Features:
- Outline generation (Ollama)
- Section content creation (Ollama)
- Slide image generation (ImageAgent)
- Obsidian note saving
"""
import logging
from typing import Dict, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class CourseProductionPipeline:
    """
    Online course auto-generation pipeline
    
    1-command course creation:
    - Table of contents
    - Section content
    - Slide images
    - Sales page generation
    - Obsid ian storage
    """
    
    def __init__(self, ollama_client=None, image_agent=None, obsidian=None, gumroad_generator=None, fish_audio=None, brain=None, groq_client=None, **kwargs):
        self.brain = brain
        self.groq_client = groq_client
        """
        Initialize with existing components
        
        Args:
            ollama_client: Ollama LLM client (from orchestrator)
            image_agent: ImageAgent instance
            obsidian: ObsidianConnector instance
            gumroad_generator: GumroadPageGenerator instance
            fish_audio: FishAudioIntegration instance
        """
        self.ollama = ollama_client
        self.image_agent = image_agent
        self.obsidian = obsidian
        self.gumroad = gumroad_generator
        self.fish_audio = fish_audio
        logger.info("CourseProductionPipeline initialized")
    
    def generate_course(self, topic: str, num_sections: int = 5, generate_narration: bool = False, reference_audio: str = None, **kwargs) -> Dict:
        """
        Generate complete course
        
        Args:
            topic: Course topic
            num_sections: Number of sections (default: 5)
        
        Returns:
            Dictionary with generation results
        """
        logger.info(f"ğŸ“ Generating course: {topic}")
        
        try:
            # --- PRIORITY 1: D1 RESEARCH INGESTION ---
            research_data = self._get_latest_research(topic)
            if research_data:
                logger.info(f"ğŸ” [D1] Found research evidence: {research_data['filename']}")
            else:
                logger.info("â„¹ï¸ [D1] No specific research found, proceeding with fallback logic")

            logger.info("Paper Knowledge injected successfully")
            if self.brain and hasattr(self.brain, 'add_memory'):
                try:
                    self.brain.add_memory("Monetization task executed", {"topic": topic, "research_used": bool(research_data)})
                except:
                    pass
            
            # Step 1: Generate outline (Informed by D1)
            outline = self._generate_outline(topic, num_sections, research_data)
            logger.info(f"âœ… Outline generated: {len(outline)} sections")
            
            # Step 2: Generate section content (Informed by D1)
            sections = self._generate_sections(outline, research_data)
            logger.info(f"âœ… Content generated: {len(sections)} sections")
            
            # Step 3: Generate slide images
            slides = self._generate_slides(sections)
            logger.info(f"âœ… Slides generated: {len(slides)} images")
            
            # Step 4: Generate sales page
            sales_page = self._generate_sales_page(topic, sections, research_data)
            if sales_page:
                logger.info(f"âœ… Sales page generated ({len(sales_page)} chars)")
            
            # Step 5: Save to Obsidian
            note_path = self._save_to_obsidian(topic, outline, sections, slides, sales_page, research_data)
            logger.info(f"âœ… Saved to Obsidian: {note_path}")
            
            return {
                "status": "success",
                "topic": topic,
                "outline": outline,
                "sections": sections,
                "slides": slides,
                "sales_page": sales_page,
                "research_source": research_data['filename'] if research_data else None,
                "obsidian_note": str(note_path)
            }
        
        except Exception as e:
            logger.error(f"âŒ Course generation failed: {e}", exc_info=True)
            return {
                "status": "error",
                "message": str(e)
            }

    def _get_latest_research(self, topic: str) -> Optional[Dict]:
        """Fetch latest relevant D1 research from Obsidian vault"""
        try:
            import pathlib
            vault_dir = pathlib.Path("obsidian_vault/knowledge")
            if not vault_dir.exists():
                return None
            
            # Find research md files (Explicitly ignore course_ files)
            files = list(vault_dir.glob("research_*.md"))
            if not files:
                logger.info("â„¹ï¸ [D1] No 'research_' files found in vault. Falling back to any non-course file.")
                all_files = list(vault_dir.glob("*.md"))
                files = [f for f in all_files if not f.name.startswith("course_")]
            
            if not files:
                return None
            
            # Sort by modification time (latest first)
            files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # Prioritize topic match in filename
            topic_match = [f for f in files if topic.lower() in f.name.lower()]
            latest_file = topic_match[0] if topic_match else files[0]
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            return {
                "filename": latest_file.name,
                "content": content,
                "mtime": latest_file.stat().st_mtime
            }
        except Exception as e:
            logger.warning(f"Failed to fetch D1 research: {e}")
            return None
        
    def _generate_outline(self, topic: str, num_sections: int, research_data: Optional[Dict] = None) -> List[str]:
        """Generate course outline informed by research"""
        
        research_context = ""
        if research_data:
            # Limit context to avoid context window explosion
            trimmed_content = research_data['content'][:4000]
            research_context = f"\n[D1 RESEARCH DATA FOUND]\n{trimmed_content}\n"

        prompt = f"""Create a course outline for "{topic}".
{research_context}

INSTRUCTION: 
If research data is provided above, prioritize the topics, evidence, and trends identified in the data.
The course should feel like an 'Intelligence Report' for the user.

Generate exactly {num_sections} section titles.
Format: Just the titles, one per line, no numbering.
"""
        
        if self.ollama:
            try:
                import re
                response = self.ollama.invoke(prompt)
                content = response.content if hasattr(response, 'content') else str(response)
                # Filter out garbage lines
                lines = [line.strip() for line in content.split('\n') if line.strip()]
                # Remove numbering and markdown markers
                outline = []
                for line in lines:
                    clean = re.sub(r'^\d+[\)\.]\s*', '', line)
                    clean = re.sub(r'[*#]', '', clean).strip()
                    if clean and len(clean) > 3:
                        outline.append(clean)
                return outline[:num_sections]
            except Exception as e:
                logger.warning(f"Ollama outline generation failed: {e}, using fallback")
        
        # Fallback outline
        return [
            f"{topic}: Introduction",
            f"{topic}: Core Concepts",
            f"{topic}: Practical Guide",
            f"{topic}: Advanced Topics",
            f"{topic}: Summary and Next Steps"
        ][:num_sections]
    
    def _generate_sections(self, outline: List[str], research_data: Optional[Dict] = None) -> List[Dict]:
        """Generate content for each section with evidence grounding"""
        sections = []
        
        research_context = ""
        if research_data:
            trimmed_content = research_data['content'][:5000]
            research_context = f"\n--- PRIMARY RESEARCH SOURCE (D1) ---\n{trimmed_content}\n"

        for i, title in enumerate(outline, 1):
            logger.info(f"ğŸ“ Generating section {i}/{len(outline)}: {title}")
            
            prompt = f"""Write detailed, EVIDENCE-BASED content for this course section:

Section Title: {title}
{research_context}

CRITICAL TASK:
Ground your explanation in the PRIMARY RESEARCH SOURCE above. 
If the research mentions specific URLs, dates, or data points relevant to this title, include them.
Focus on 'Why this works in 2026' and provide actionable insights.
Keep a professional yet supportive tone.

Write 3-5 informative paragraphs.
Content:"""
            
            content = ""
            if self.ollama:
                try:
                    response = self.ollama.invoke(prompt)
                    content = response.content if hasattr(response, 'content') else str(response)
                except Exception as e:
                    logger.warning(f"Ollama section generation failed: {e}")
            
            if not content:
                content = f"**{title}**\n\nThis section covers important aspects of {title}. Key concepts will be explained with practical examples and real-world applications."
            
            sections.append({
                "number": i,
                "title": title,
                "content": content
            })
        
        return sections
    
    def _generate_slides(self, sections: List[Dict]) -> List[Dict]:
        """Generate slide images"""
        slides = []
        
        for section in sections:
            logger.info(f"ğŸ–¼ï¸  Generating slide {section['number']}: {section['title']}")
            
            # Professional slide prompt
            prompt = f"Professional course slide with title '{section['title']}', minimal text, clean design, educational style, high quality"
            
            try:
                if self.image_agent:
                    result = self.image_agent.generate_image(prompt)
                    if result and result.get("status") == "success":
                        slides.append({
                            "section": section['number'],
                            "title": section['title'],
                            "image_path": result.get("path"),
                            "image_url": result.get("url")
                        })
                        continue
            except Exception as e:
                logger.error(f"Slide generation error: {e}")
            
            # If image generation fails, still record the section
            slides.append({
                "section": section['number'],
                "title": section['title'],
                "status": "image_generation_skipped"
            })
        
        return slides
    
    def _generate_sales_page(self, topic: str, sections: List[Dict], research_data: Optional[Dict] = None) -> Optional[str]:
        """
        Generate sales page framed as 'battle log as an asset'.

        Positioning: The buyer is not purchasing a course.
        They are purchasing the actual operational log â€” the raw intelligence
        that Sage produced during a live research-and-execution run.
        Proof-of-work is the product itself.
        """

        if not self.ollama:
            logger.warning("Ollama not available for sales page generation")
            return None

        try:
            # --- Build proof-of-work evidence block from real artifacts ---
            evidence_lines = []
            if research_data:
                evidence_lines.append(f"- ä¸€æ¬¡æƒ…å ±ã‚½ãƒ¼ã‚¹: `{research_data['filename']}`ï¼ˆD1ãƒªã‚µãƒ¼ãƒãƒ«ãƒ¼ãƒ—å–å¾—æ¸ˆã¿ï¼‰")
                # Extract first non-empty line as a teaser quote
                for line in research_data['content'].splitlines():
                    stripped = line.strip()
                    if stripped and not stripped.startswith('#') and len(stripped) > 20:
                        evidence_lines.append(f'- ãƒ­ã‚°æŠœç²‹: ã€Œ{stripped[:120]}â€¦ã€')
                        break

            ops_log = "\n".join(
                f"  - Ops {s['number']:02d}: {s['title']}" for s in sections
            )
            evidence_block = "\n".join(evidence_lines) if evidence_lines else "- ä¸€æ¬¡æƒ…å ±ã‚½ãƒ¼ã‚¹: æ±ç”¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆD1ãƒˆãƒ¬ãƒ¼ã‚¹æœªå–å¾—ï¼‰"

            prompt = f"""ã‚ãªãŸã¯ã€Œå®Ÿæˆ¦ãƒ­ã‚°ã‚’è³‡ç”£ã¨ã—ã¦è²©å£²ã™ã‚‹ã€ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

ä»¥ä¸‹ã®åˆ¶ç´„ã‚’å³å®ˆã—ã¦ãã ã•ã„:
- ã€Œã‚³ãƒ¼ã‚¹ã€ã€Œè¬›åº§ã€ã€Œå­¦ç¿’ã€ã¨ã„ã†è¨€è‘‰ã‚’ä¸€åˆ‡ä½¿ã‚ãªã„
- å£²ã£ã¦ã„ã‚‹ã®ã¯ã€ŒSage AIãŒå®Ÿéš›ã«å‹•ã„ãŸæ™‚ã®ä½œæˆ¦è¨˜éŒ²ï¼ˆå®Ÿæˆ¦ãƒ­ã‚°ï¼‰ã€ã§ã‚ã‚‹
- è³¼å…¥è€…ã¯ã€Œä½“é¨“ã‚’è²·ã†ã€ã®ã§ã¯ãªãã€Œå†ç¾å¯èƒ½ãªè«œå ±è³‡ç”£ã‚’æ‰‹ã«å…¥ã‚Œã‚‹ã€
- è¨¼æ‹ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åãƒ»ãƒ­ã‚°æ–­ç‰‡ï¼‰ã‚’å…·ä½“çš„ã«å¼•ç”¨ã™ã‚‹

---
ã€ä»Šå›ã®å®Ÿæˆ¦ãƒ­ã‚°ã€‘
ãƒ†ãƒ¼ãƒ: {topic}
ä½œæˆ¦è¨˜éŒ² (Ops Log):
{ops_log}

ã€ä¸€æ¬¡è¨¼æ‹ ã€‘
{evidence_block}
---

ä»¥ä¸‹ã®æ§‹æˆã§Gumroadè²©å£²ãƒšãƒ¼ã‚¸ï¼ˆMarkdownï¼‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:

## 1. ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆ1è¡Œï¼‰
ã€Œã“ã‚Œã¯ã‚³ãƒ¼ã‚¹ã§ã¯ãªã„ã€‚{topic}ã®å®Ÿæˆ¦è¨˜éŒ²ã ã€‚ã€ã®æ–¹å‘ã§ã€‚

## 2. ã“ã®ãƒ­ã‚°ãŒç”Ÿã¾ã‚ŒãŸèƒŒæ™¯ï¼ˆ3-4æ–‡ï¼‰
Sage AIãŒå®Ÿéš›ã«ãƒªã‚µãƒ¼ãƒãƒ»åˆ¤æ–­ãƒ»å®Ÿè¡Œã—ãŸãƒ—ãƒ­ã‚»ã‚¹ã®æ¦‚è¦ã€‚
ã€Œèª°ã‹ãŒä½œã£ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€ã§ã¯ãªãã€ŒAIãŒç¨¼åƒã—ãŸè¨¼æ‹ ã€ã¨ã—ã¦èªã‚‹ã€‚

## 3. ä¸€èˆ¬çš„ãªæƒ…å ±ã¨ã®é•ã„ï¼ˆç®‡æ¡æ›¸ã3ç‚¹ï¼‰
- ã»ã¨ã‚“ã©ã®æƒ…å ±å•†æã¯ç†è«–ã€‚ã“ã‚Œã¯å®Ÿè¡Œãƒ­ã‚°ã€‚
- ä½œæˆè€…ã®ä¸»è¦³ã§ã¯ãªãã€AIã®åˆ¤æ–­ãƒˆãƒ¬ãƒ¼ã‚¹ãŒãã®ã¾ã¾å…¥ã£ã¦ã„ã‚‹ã€‚
- D1ãƒªã‚µãƒ¼ãƒãƒ«ãƒ¼ãƒ—ã§å–å¾—ã—ãŸä¸€æ¬¡æƒ…å ±ãŒæ ¹æ‹ ã«ãªã£ã¦ã„ã‚‹ã€‚

## 4. ãƒ­ã‚°ã®ä¸­èº«ï¼ˆä½œæˆ¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼‰
å„Opsã®åç§°ã‚’ãã®ã¾ã¾åˆ—æŒ™ã€‚ã€Œå†ç¾æ‰‹é †æ›¸ã€ã¨ã—ã¦ä½ç½®ä»˜ã‘ã‚‹ã€‚

## 5. èª°ãŒè²·ã†ã¹ãã‹ï¼ˆ2-3ç‚¹ï¼‰
ã€ŒåŒã˜çµæœã‚’è‡ªåˆ†ã§å†ç¾ã—ãŸã„äººã€ã€ŒAIã®å®Ÿéš›ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ç ”ç©¶ã—ãŸã„äººã€ãªã©ã€‚

## 6. ä¾¡æ ¼ã¨å¸Œå°‘æ€§
ã“ã®ãƒ­ã‚°ã¯ã€Œã“ã®ãƒˆãƒ”ãƒƒã‚¯ãƒ»ã“ã®æ—¥æ™‚ãƒ»ã“ã®ãƒ‡ãƒ¼ã‚¿ã€ã®ä¸€ç‚¹ã‚‚ã®ã€‚
åŒã˜æ¡ä»¶ã§ã¯äºŒåº¦ã¨ç”Ÿæˆã•ã‚Œãªã„ç†ç”±ã‚’1-2æ–‡ã§ã€‚

## 7. CTA
è³¼å…¥ãƒœã‚¿ãƒ³ã«æ·»ãˆã‚‹ã‚³ãƒ”ãƒ¼ï¼ˆ1è¡Œï¼‰ã€‚

å‡ºåŠ›ã¯Markdownã®ã¿ã€‚ä½™åˆ†ãªå‰ç½®ãã¯ä¸è¦ã€‚
"""

            response = self.ollama.invoke(prompt)
            sales_page = response.content if hasattr(response, 'content') else str(response)

            # Prepend a machine-readable metadata header for Obsidian / downstream parsers
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
            header = (
                f"<!-- SAGE_SALES_PAGE | topic={topic} | "
                f"source={research_data['filename'] if research_data else 'none'} | "
                f"generated={timestamp} -->\n\n"
            )
            return header + sales_page

        except Exception as e:
            logger.error(f"Sales page generation failed: {e}")
            return None
    
    def _save_to_obsidian(self, topic: str, outline: List[str], 
                          sections: List[Dict], slides: List[Dict], sales_page: Optional[str] = None,
                          research_data: Optional[Dict] = None) -> Optional[str]:
        """Save course to Obsidian with Research Traceability"""
        
        if not self.obsidian:
            logger.warning("Obsidian not configured, skipping save")
            return None
        
        # Build Markdown content
        content = f"# {topic} - Course Content\n\n"
        content += f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
        
        # Table of contents
        content += "## ğŸ“‹ Course Outline\n\n"
        for i, title in enumerate(outline, 1):
            content += f"{i}. {title}\n"
        content += "\n---\n\n"
        
        # Section details
        for section in sections:
            content += f"## {section['number']}. {section['title']}\n\n"
            content += section['content']
            content += "\n\n"
            
            # Add slide image reference if available
            slide = next((s for s in slides if s['section'] == section['number']), None)
            if slide and 'image_path' in slide:
                content += f"**Slide**: `{slide['image_path']}`\n\n"
            
            content += "---\n\n"
        
        # Add sales page if available
        if sales_page:
            content += "## ğŸ’° Sales Page & Gumroad Pitch\n\n"
            content += sales_page
            content += "\n\n---\n\n"
            
        content += "## ğŸ§ª Research Context & Evidence (D1 Traceability)\n\n"
        content += f"- **Topic/Query**: {topic}\n"
        if research_data:
            content += f"- **Primary Evidence Source**: `{research_data['filename']}`\n"
            content += f"- **Evidence Authenticity**: Verified via D1 Loop\n"
        else:
            content += "- **Primary Evidence**: General Knowledge (No D1 Trace found)\n"
            
        content += f"- **Generated At**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        content += "- **Sage Version**: 3.0 Fortress\n\n"
        content += "---\n\n"
        
        try:
            if hasattr(self.obsidian, 'create_knowledge_note'):
                note_path = self.obsidian.create_knowledge_note(
                    content,
                    {
                        "topic": topic,
                        "type": "course",
                        "status": "generated",
                        "generated_at": datetime.now().isoformat()
                    }
                )
                return str(note_path)
            else:
                # Write directly to bypass error
                import os, time
                import pathlib
                vault_dir = pathlib.Path("obsidian_vault/knowledge")
                vault_dir.mkdir(parents=True, exist_ok=True)
                note_name = f"course_{int(time.time())}.md"
                note_path = vault_dir / note_name
                with open(note_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Directly wrote note to {note_path}")
                return str(note_path)
        except Exception as e:
            logger.error(f"Obsidian save failed: {e}")
            return None
